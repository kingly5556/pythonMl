What is Cross-Validation?
-Statical method used to evaluate the performance of a model by partitioning the data onto training and validation subsets multiple times
-It helps ensure that the model's performance generalizes well to unseen data
-Why use Cross-Validation?
    Prevents overfitting
        By evaluating the model on multiple subsets,cross-validation provides a more robust measure of its performance
    Reliable Performance Estimate
        Reduces the variance of performance metrics compared to a singke train_test_split
    Optimizes Model Selection
        Helps in comparing and selecting the best model or hyperparameter configuration.
-Type of cross-validation
    K-Fold cross-validation
        split the dataset into K equal-sized folds
        Train the model on K-1Folds and validates on the remaining fold
        Repeats the process K times,ensuring each fold is used as a validation set once
        Best for:general-purpose datasets.
    Stratified K-Fold Cross-Validation
        Ensures that each folr maintains the same class distribution as the original dataset
        Particularly useful for imbalanced datasets
        Best For:Classification tasks with imbalanced data
    Leave-One-Out Cross-Validation(LOOCV)
        Uses a single data point as the validation set and the rest as the training set
        Repeats the process for each data point
        Pros:Maximizes training data for each fold
        Cons:Computationally expensive for large datasets
        Best For:Small datasets where maximizing training data is critical
-Practical Guidance on Cross-Validation
    Choose K based on Data size
        K = 5 or K = 10are commonly used for large datasets
        Use LOOCV for small datasets
    Stratification for Imbalanced Data
        Always prefer Stratified K-Fold for imbalanced classification task to ensure fair evaluation
    Combinde with HyperParameter Tuning
        Integrate Cross-Validation into Grid or Random Search robust hyperparameter tuning
    