Concepts
-What is ensemble leaning?
    Machine Learning technique that combines the predictions of multiple models to produce a final output
-Why Does ensemble learning improve performance?
    Reduces Variance
    Reduces Bias
    Improves RoBustness
-Applications
    Flaud detection,medical diagnoses,recommentdation systems,and predictive analytics

Types of ensemble methods
-Bagging(Bootstrap Aggregating)
    Trains multiple models independently on different subset of data created through bootstrapping
    Combines predictions by averaging(regression)or majority voting(classification)
    Exam:Random Forest
    Strengths:Reduces variance without increasing bias
-Boosting
    Trains models sequentially,where each model focuses on orrecting the errors mad by the previous ones
    Combines predictions through weighted averaging or voting
    Exam:Adaboost,gradient boosting,XGboost,LightGBM
    Strength:Reduces both bias and variance by focusing on hard-to-predict instances
-Stacking
    Combines predictions from multiple base models(of different types)using a meta-model to learn how to best combine their outputs
    Strengths:Can utilize diverse model types to maximize performance