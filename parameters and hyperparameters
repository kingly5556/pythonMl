What are Parameterss
    Values Learned by a machine learning model during training.
    Adjusted to minimize the loss function and optimize predictions
    Examples:
        Coefficients in Linear Regression
        Weights and biases in Neural Networks
What are Hyperparameters?
    Settings defined before training that influence how the model learns from data
    Not learning from the data but instead control the training process
    Examples:
        Tree Depth
        Learning Rate
        Number of Estimators
Important of tuning Hyperparameters
-Why tune Hyperparameters?
    Improve Model performance
        Optimal hyperparameters help models generalize better,reducing overfitting and underfitting
    Enhance Efficiency
        Proper tuning can reduce training time and computational resources
    Adapt to Problem-Specific Needs
        Tailoring hyperparameters ensures the model fits the dataset's characteristics

Common Hyperparameters in popular models
-Decision Trees and Random Forests
    Max Depth:Limits the depth of trees to avoid overfitting.
    Min Sample Split:Minimum sample required to split an internal node.
    Number of estimators:Total numver of trees in random forest.
-Gradient Boosting Models
    LearningRate:Determines the contribution of each tree.
    Subsample:Fraction of training data used to train each tree.
    Max depth:Limits the complexity to individual trees.
-Neural Networks
    Learning rate:Step size for weight updates.
    Number of Layers:Determines the depth of the network.
    Batch Size:Number of samples per gradient update.

