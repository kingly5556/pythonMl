Regression metrics
-Mean Absolute error
    Measures the average magnitude of errors without considering their direction
    Use case:Suitable when all errors have equal importance
-Mean Squared error
    Measures the average of squared differences between actual and predicted values
    Use case:Penalizes larger errors more than MAE,makjng it sensitive to outliers
-Root mean Squared Error
    Square root of MSE,providing erroes in the same units as the target variable
    Use case:A common metric for interpretability in real-world units
-R-squared
    Measures how well the model explains the variability of the target variable
    Use case:Indicates the proportion of variance explained by the model

Classification metrics    
-Accuracy
    Percentage of correctly classified instances
    Use case:Suitable for balanced datasets but misleading for imbalanced data
-Precision
    Fraction of true positives identified among all actual positives
    Use case:Critical in situations where missing positives is costle
Recall(Sensitivity)
    Fraction of true positives identified among all actual positives
    Use case:Critical in situations where missing positives in costly
F1 Score
    Harmonic mean of precision and recall
    Use case:Useful imbalanced datasets
ROC-AUC
    Measures the ability of the model to distinguish between classes 
    Use case:Important for evaluating binary classifiers

Understanding when to use each metric
-Regression
    Use MAE for interpretability and uniform importance of error
    Use MSE/RMSE when larger error need greater penalization
    Use R*R to explain variance but not as a sole performance metic
-Classification
    Use accuracy for balanced datasets
    Use precision and recall for imbalanced datasets,depending on the problem's focus(minimizing false positives or false negatives)
    Use F! score for a balanced evaluation of precision and recall
    Use ROC-AUC for overall model performance evaluation in binary classification
